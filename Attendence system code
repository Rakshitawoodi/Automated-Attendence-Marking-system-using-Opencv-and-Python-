import numpy as np
import cv2
import os
import face_recognition
def assure_path_exists(path):
    dir = os.path.dirname(path)
    if not os.path.exists(dir):
        os.makedirs(dir)


face_id = input('enter your id ')
# Start capturing video
vid_cam = cv2.VideoCapture(0)

# Detect object in video stream using Haarcascade Frontal Face
face_detector = cv2.CascadeClassifier('C:\\Users\\RAKSHITA\\downloads\\haarcascade_frontalface_default.xml')

# Initialize sample face image
count = 0

assure_path_exists("C:\\Users\\RAKSHITA\\PycharmProjects\\automaticattendencesystem\\practise2.py")

# Start looping
while (True):

    # Capture video frame1
    _, image_frame = vid_cam.read()

    # Convert frame to grayscale
    gray = cv2.cvtColor(image_frame, cv2.COLOR_BGR2GRAY)

    # Detect frames of different sizes, list of faces rectangles
    faces = face_detector.detectMultiScale(gray, 1.3, 5)

    # Loops for each faces
    for (x, y, w, h) in faces:
        # Crop the image frame into rectangle
        cv2.rectangle(image_frame, (x, y), (x + w, y + h), (255, 0, 0), 2)
        # Increment sample face image
        count += 1

        # Save the captured image into the datasets folder
        cv2.imwrite('C:\\Users\\RAKSHITA\\PycharmProjects\\automaticattendencesystem\\images\\' + str(face_id) + '.' + str(count) + ".jpg", gray[y:y + h, x:x + w])

        # Display the video frame, with bounded rectangle on the person's face
        cv2.imshow('frame', image_frame)

    # To stop taking video, press 'q' for at least 100ms
    if cv2.waitKey(1) & 0xFF == ord('q'):
        print("Successfully Captured")
        break

# Stop video
vid_cam.release()

# Close all started windows
cv2.destroyAllWindows()
img = face_recognition.load_image_file('C:\\Users\\RAKSHITA\\PycharmProjects\\automaticattendencesystem\\images\\' + str(face_id) + '.' + str(5) + ".jpg")
img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
face_loc = face_recognition.face_locations(img)[0]
encoding = face_recognition.face_encodings(img)[0]
cv2.rectangle(img, (face_loc[3], face_loc[0]), (face_loc[1], face_loc[2]), (200, 170,90), 2)

img1 = face_recognition.load_image_file("C:\\Users\\RAKSHITA\\Desktop\\images\\Raks.jpg")
img1 = cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)
imgre1 = cv2.resize(img1, (350, 350))
face_loc1 = face_recognition.face_locations(imgre1)[0]
encoding1 = face_recognition.face_encodings(imgre1)[0]
cv2.rectangle(imgre1, (face_loc1[3], face_loc1[0]), (face_loc1[1], face_loc1[2]), (200, 170,90), 2)

results = face_recognition.compare_faces([encoding],encoding1 )
if (results[0] ==True):
    print("attendence marked")
    face_dist = face_recognition.face_distance([encoding], encoding1)
    cv2.imshow("image", img)
    cv2.imshow("image1", imgre1)
    cv2.waitKey(0)
else:
    cv2.imshow("image", img)
    cv2.imshow("image1", imgre1)
    print("attendence not marked")
    cv2.waitKey(0)
